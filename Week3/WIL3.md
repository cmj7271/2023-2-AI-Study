# Week3

---

이번 주차 실습은 MLP를 통한 MNIST 데이터 학습이었다.  

먼저 학습을 위한 `device` 를 설정했는데, 맥북을 사용하는 중이라, nvidia 의 cuda 는 사용할 수 없었다.  
이에 비교적 최신에 업데이트된 `mps` (Metal Performance Shaders) 를 사용하기로 했다.  
(~~이때는 이게 재앙인지 몰랐지~~)  
하지만, 어떤 에러인지 뜨지 않고 kernel 이 crash 이 되고, cpu 보다 느린 점 때문에  cpu로 진행했다…

이번 학습에서 사용하는 MNIST 데이터는 0~10에 대한 손글씨를 28 * 28 픽셀로 표현한 데이터이다.  
모델에 대한 학습에 있어서 기본적으로 사용하는 데이터로 상대적으로 단순하다.  
이 데이터에 대해 MLP 즉 멀티 퍼셉트론 모델을 사용하게 되었다.

MLP 의 기본구조인 퍼셉트론은 모든 데이터와 가중치 쌍으로 곱한 것들의 합이  
임계치보다 높으면(혹은 편향값(`bias`) 를 뺀 값이 0보다 크면) 1을 출력하는 단순한 모델이다.  

해당 데이터를 모델에 맞게 가공하는 과정을 거쳐야 하는데, 이를 위해  
28 * 28 인 2차원 데이터를 784 * 1 로 바꾸어 주었으며, 데이터셋을 하나에 256개의 데이터가 들어가도록  
쪼개주었다. 즉, 하나의 미니데이터셋은 [256, 784] 으로 이루어져 있다.  

## 시행착오

---

이 때 한가지 고생한 내용이 있는데, 전체 데이터셋이 256개로 나누어떨어지지 않는다는 점이었다.  
미니데이터셋의 사이즈를 256으로 정했기 때문에 모든 데이터셋이 그럴줄 알았지만….  
마지막 데이터셋은 전체 데이터의 개수가 256으로 나누어떨어지지 않기 때문에  
256개가 아니었다. 이 점을 간과하여 상당히 애를 먹었다….  
해결은 각 미니데이터셋의 0차원을 고려한 변환(256으로 고정된것이 아닌)으로 해결했다.

이 문제에 직면했을 당시는 디바이스가 `mps` 였다. 이 때문에 에러가 아닌 `kernel` 이 죽어버렸기 때문에  
`mps` 가 문제인 줄 알고, `mps` 에 대한 정보만 찾고있었다…  

후에 혹시나 하는 마음으로 `cpu` 로 진행하니, 대응하는 텐서의 shape 이 맞지 않다는 에러를 만났고,  
이때부터 input 데이터의 shape 에 집중하여 찾을 수 있었다.

## 용어 정리

---

실습하면서 헷갈렸던 몇 개의 용어를 정리했다.  

- batch_size
    
    하나의 작은 데이터셋에서의 데이터 개수이다.  
    만약 전체 데이터가 700개, batch_size 가 100 이라면,  
    하나의 작은 데이터셋은 100개의 데이터를 가지며, 그런 작은 데이터셋이 7개가 있다.
    
- epoch
    
    전체 데이터셋이 신경망을 통과한 횟수를 의미한다.  
    위의 예시를 그대로 사용하면서, epoch가 2라고 가정하면,  
    7개의 모든 작은 데이터셋이 2번, 즉 신경망은 14번 학습했다.
    
- iteration
    
    검색하다보니 같이 있어서 정리했다.  
    epoch 1번을 만족하기 위해 필요한 학습 횟수이다.  
    위의 예시로는 7개의 작은 데이터셋이 있으므로 7이 된다.