# Week5

지난 시간에는 물체를 영역으로 구분하여 판별하는 Object Detection 을 배웠다.

다음으로는 물체를 식별하고 경계를 구별하는 Semantic Segmentation 을 공부하게 되었다.

먼저 단어의 의미부터 파악해보자.

> semantic : 의미의, 의미론의
> 

> segmentation : 분할
> 

즉, 컴퓨터가 의미를 파악하고 알아서 영역을 구분해준다고 할 수 있다.

마치 우리 인간이 사진을 보고, 사람이 몇명있고, 배경은 바다이며, 새가 여러마리 날아다닌다~라고 파악하는 것과 유사하다.

이 것이 어떻게 가능할까? 지금부터 살펴보자.

가장 먼저 비슷비슷해보이는 Classification 과 Detection 과 Segmentation 을 구분하고 넘어가자.

classification 은 주어진 인풋에 대해 하나의 답을 예측해내는 것이며,

Detection 은 여러개를 레이블을 예측하고, 구역으로써 그들을 구분해준다.

Segmentation 은 구분을 넘어서 실제 해당 레이블의 경계를 찾아준다.

다른 말로는 **모든** 픽셀에 대해 레이블을 구분해주는 것으로 보아도 무방하다.

이번에는 Semantic Segmentation 을 수행하는 모델 중 FCN을 공부할 것이다.

FCN 은 이전의 분류 모델들의 단점을 보완하여 만들어진 모델이다.

그렇다면 어떤 단점들이 있었을까?

이전 모델들은 기본적으로 Fully-connected layer 를 마지막 출력층으로 구현하였다.

하지만, FC layer는 위치정보가 사라지고(1차원으로 평탄화하기 때문에), 크기가 정해져있다(이미지 크기에 따라 가중치의 개수가 달라진다)는 문제점이 있다.

이에 FCN 은 기존의 모델에서 마지막 출력층을 Convolution layer 로 교체했다.

이로써 위치정보를 보존시키고(크기만 압축되기 때문에), 이미지 크기에 영향을 받지 않게(convolution 연산의 특징 때문) 되었다.

마지막을 convolution layer 로 바꾸게 되면서, 크기를 다시 키워줘야했고, 이에 도입한 방법이

Deconvolution 이었다.

마지막으로 FCN 을 모델까지만 간단하게 구현하는 과제를 하게 되었는데,

생각보다 쉬워서 당황했다. 물론 기본적으로 구조가 짜여저있어서 그런 점도 있겠지만,

in_channel, out_channel, pedding, stride 만 잘 신경써주면 된다는 점이, 프레임워크의 장점을 알 듯하다.

또한, 반대로 처음부터 구현하는 것도 한번쯤은 필요하겠다는 생각이 든다.

내부적으로 정확히 어떻게 돌아가는지 모르는 블랙박스인 채로는 발전이 없을테니말이다.